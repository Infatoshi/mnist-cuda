{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_train = datasets.MNIST(root='/mnt/d/CUDA/cuda-learn/mnist-cuda/data', train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "X_train = mnist_train.data.numpy().reshape(-1, 1, 28, 28) / 255.0\n",
    "y_train = mnist_train.targets.numpy()\n",
    "X_test = mnist_test.data.numpy().reshape(-1, 1, 28, 28) / 255.0\n",
    "y_test = mnist_test.targets.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer:\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        self.w = np.random.randn(out_channels, in_channels, kernel_size, kernel_size) * np.sqrt(2. / (in_channels * kernel_size * kernel_size))\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = np.pad(x, ((0,0), (0,0), (self.padding,self.padding), (self.padding,self.padding)), mode='constant')\n",
    "        n, c, h, w = self.x.shape\n",
    "        out_h = (h - self.w.shape[2]) // self.stride + 1\n",
    "        out_w = (w - self.w.shape[3]) // self.stride + 1\n",
    "        out = np.zeros((n, self.w.shape[0], out_h, out_w))\n",
    "\n",
    "        for i in range(out_h):\n",
    "            for j in range(out_w):\n",
    "                out[:, :, i, j] = np.sum(self.x[:, np.newaxis, :, i*self.stride:i*self.stride+self.w.shape[2], j*self.stride:j*self.stride+self.w.shape[3]] * self.w[np.newaxis, :, :, :, :], axis=(2,3,4))\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        n, _, out_h, out_w = dout.shape\n",
    "        dx = np.zeros_like(self.x)\n",
    "        dw = np.zeros_like(self.w)\n",
    "\n",
    "        for i in range(out_h):\n",
    "            for j in range(out_w):\n",
    "                x_slice = self.x[:, :, i*self.stride:i*self.stride+self.w.shape[2], j*self.stride:j*self.stride+self.w.shape[3]]\n",
    "                for k in range(self.w.shape[0]):  # out_channels\n",
    "                    dx[:, :, i*self.stride:i*self.stride+self.w.shape[2], j*self.stride:j*self.stride+self.w.shape[3]] += self.w[k, :, :, :] * dout[:, k, i, j][:, np.newaxis, np.newaxis, np.newaxis]\n",
    "                    dw[k, :, :, :] += np.sum(x_slice * dout[:, k, i, j][:, np.newaxis, np.newaxis, np.newaxis], axis=0)\n",
    "\n",
    "        return dx[:, :, self.padding:-self.padding, self.padding:-self.padding], dw\n",
    "\n",
    "class ReLU:\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        return dout * (self.x > 0)\n",
    "\n",
    "class MaxPool:\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        n, c, h, w = x.shape\n",
    "        out_h = (h - self.kernel_size) // self.stride + 1\n",
    "        out_w = (w - self.kernel_size) // self.stride + 1\n",
    "        out = np.zeros((n, c, out_h, out_w))\n",
    "\n",
    "        for i in range(out_h):\n",
    "            for j in range(out_w):\n",
    "                out[:, :, i, j] = np.max(x[:, :, i*self.stride:i*self.stride+self.kernel_size, j*self.stride:j*self.stride+self.kernel_size], axis=(2,3))\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        n, c, out_h, out_w = dout.shape\n",
    "        dx = np.zeros_like(self.x)\n",
    "\n",
    "        for i in range(out_h):\n",
    "            for j in range(out_w):\n",
    "                window = self.x[:, :, i*self.stride:i*self.stride+self.kernel_size, j*self.stride:j*self.stride+self.kernel_size]\n",
    "                mask = window == np.max(window, axis=(2,3))[:, :, np.newaxis, np.newaxis]\n",
    "                dx[:, :, i*self.stride:i*self.stride+self.kernel_size, j*self.stride:j*self.stride+self.kernel_size] += mask * dout[:, :, i:i+1, j:j+1]\n",
    "\n",
    "        return dx\n",
    "\n",
    "class Linear:\n",
    "    def __init__(self, in_features, out_features):\n",
    "        self.w = np.random.randn(out_features, in_features) * np.sqrt(2. / in_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return self.w @ x\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = self.w.T @ dout\n",
    "        dw = dout @ self.x.T\n",
    "        return dx, dw\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=0, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=0, keepdims=True)\n",
    "\n",
    "def cross_entropy_loss(y_pred, y_true):\n",
    "    m = y_pred.shape[1]\n",
    "    p = softmax(y_pred)\n",
    "    log_likelihood = -np.log(p[y_true, range(m)])\n",
    "    loss = np.sum(log_likelihood) / m\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "    def __init__(self):\n",
    "        self.conv1 = ConvLayer(1, 32, 3, padding=1)\n",
    "        self.relu1 = ReLU()\n",
    "        self.pool1 = MaxPool(2, 2)\n",
    "        self.fc1 = Linear(32 * 14 * 14, 128)\n",
    "        self.relu2 = ReLU()\n",
    "        self.fc2 = Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1.forward(x)\n",
    "        x = self.relu1.forward(x)\n",
    "        x = self.pool1.forward(x)\n",
    "        x = x.reshape(x.shape[0], -1).T\n",
    "        x = self.fc1.forward(x)\n",
    "        x = self.relu2.forward(x)\n",
    "        x = self.fc2.forward(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx, fc2_grad = self.fc2.backward(dout)\n",
    "        dx = self.relu2.backward(dx)\n",
    "        dx, fc1_grad = self.fc1.backward(dx)\n",
    "        dx = dx.T.reshape(dx.shape[1], 32, 14, 14)\n",
    "        dx = self.pool1.backward(dx)\n",
    "        dx = self.relu1.backward(dx)\n",
    "        dx, conv_grad = self.conv1.backward(dx)\n",
    "\n",
    "        return conv_grad, fc1_grad, fc2_grad\n",
    "\n",
    "    def update_weights(self, conv_grad, fc1_grad, fc2_grad, lr):\n",
    "        self.conv1.w -= lr * conv_grad\n",
    "        self.fc1.w -= lr * fc1_grad\n",
    "        self.fc2.w -= lr * fc2_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "x [[-1.07044245  0.13596827 -1.32996639 -0.99620496 -0.79739503 -1.27682437\n",
      "  -0.34272166 -1.00011977]\n",
      " [ 0.27400307 -1.27866596  0.05606223 -0.16121898  0.14167424 -0.01761839\n",
      "   0.10880915 -0.34056737]\n",
      " [-0.07350263  1.09572228 -0.48280026  0.5746928   0.34449629  0.39360367\n",
      "   0.09705935  0.29644265]\n",
      " [ 0.95324341  1.2045214   0.72340892  1.46262121  0.68226038  1.30596765\n",
      "   0.67848064  0.97305164]\n",
      " [-0.64309287 -0.87903675 -1.1399119  -0.61352891 -0.31333153 -0.29652845\n",
      "  -0.3032795  -1.18670081]\n",
      " [ 0.28541913  0.47777098  0.27998578  0.81787153  0.39139849  0.25532893\n",
      "  -0.33666057  0.59888357]\n",
      " [ 0.45380309  0.36364664  1.09854901  0.30448143  0.85019439  0.08105874\n",
      "   0.69586024  0.35792112]\n",
      " [ 0.68530295  0.62874532  0.24575791  0.37754707  0.99428215  0.653464\n",
      "   1.02416533  0.5207731 ]\n",
      " [ 0.84454503  0.46884591  0.32904396  0.4284976   0.55916584  0.68165923\n",
      "   0.03421627  0.59979756]\n",
      " [-1.53917302 -1.24115726 -1.18989536 -0.99356163 -0.5215085  -0.74545906\n",
      "  -0.62775178 -1.35700879]]\n",
      "Iter: 0 Loss: 2.5913559889344184\n",
      "x [[-0.24774112 -1.05786896 -0.42343667 -0.73977283 -0.20600512 -0.09816799\n",
      "  -0.4934418  -0.52558459]\n",
      " [ 0.37125278 -0.25675202  0.07773401 -0.03461846  0.49674112  0.07795771\n",
      "   0.43255862 -0.59019717]\n",
      " [ 0.42311172  0.31477901  0.42955097  0.12196216  0.67735785  0.47236364\n",
      "   0.31153012  0.80078555]\n",
      " [ 0.43125861  1.60533084  0.97299864  1.46237558  0.26637397  1.44052217\n",
      "   0.52676466  1.04864139]\n",
      " [-0.52971804 -0.69415806 -0.51825824 -0.34764814 -1.439442   -0.79740962\n",
      "  -0.43121321 -0.41887861]\n",
      " [-0.38042019  0.40694904  0.42923378  0.00505692  0.48362119  0.26754564\n",
      "  -0.41520885  0.19387481]\n",
      " [ 0.37408607  0.53395644  0.13472263  0.29900556 -0.050959    0.00988932\n",
      "   0.64531384  0.49443882]\n",
      " [ 1.13275757  0.59203117  0.04804103  0.35575292  0.30146452  0.54911884\n",
      "   0.61890277  0.33457449]\n",
      " [-0.13244376  0.22904393  0.61126727  0.23747696  0.78824849  0.48285387\n",
      "  -0.10541265  0.65493821]\n",
      " [-0.51690055 -0.43078866 -1.63080613 -0.45530472 -2.27992468 -0.88511796\n",
      "  -0.27728553 -0.49274614]]\n",
      "x [[-0.81592742 -1.12357893 -0.72749082 -0.73163469  0.03485545 -0.05463745\n",
      "  -0.90918934 -1.03327168]\n",
      " [-0.17022258  0.22985336  0.49438845  0.18751014 -0.09954515 -1.37824506\n",
      "   0.18794397  0.03194829]\n",
      " [ 0.39664818  0.31752503 -0.00964437  0.3578155  -0.20499134  1.28566064\n",
      "   0.39220782  0.44625   ]\n",
      " [ 0.86042988  1.11396289  0.23664837  1.24418492  0.57478302  1.2795117\n",
      "   0.84623968  1.29986266]\n",
      " [-0.92465074 -0.06791124 -0.55631266 -0.37521368 -0.98534595 -0.84769224\n",
      "  -0.0226112  -0.66066814]\n",
      " [ 0.31871193  1.19091193  0.48738482  0.65577153  0.72062518  0.78964908\n",
      "   0.97279212  0.79395404]\n",
      " [-0.39561493  0.52617969  0.50589849 -0.04546978  0.40852748  0.19571243\n",
      "   0.66234768  0.28605724]\n",
      " [-0.159821    0.80308414  0.36964822  0.5353166   0.50261935  0.94215498\n",
      "   0.39484513  0.38040821]\n",
      " [ 0.22792303  0.57649159  0.19163138  0.3216789  -0.36400801  0.67547032\n",
      "   0.25853582  0.31738209]\n",
      " [-1.54118266 -0.91249631 -1.01819415 -0.80597213 -1.32604448 -0.91352631\n",
      "  -0.5993885  -0.80525696]]\n",
      "x [[-0.10444185 -0.49757222 -0.7080266  -0.22412626 -0.91734876  0.01983436\n",
      "  -0.16031923 -1.27141492]\n",
      " [ 0.22366282 -0.3834056   0.70253792 -0.53856709 -0.86669992  0.58283555\n",
      "   0.83943164 -0.41332445]\n",
      " [ 0.5701939  -0.10434831  0.24064721  0.492617    0.35241805  0.24768942\n",
      "   0.17595448  0.12061971]\n",
      " [ 0.59573312  0.60299538  0.3188075   0.7739875   0.62806116  1.00209357\n",
      "   0.22152191  1.18501737]\n",
      " [-0.02426215 -0.49530508 -0.29872454 -1.20196474 -0.49809416 -0.14450866\n",
      "  -0.70896418 -0.25833051]\n",
      " [ 0.4726582   0.51873192  0.16742842  0.32209598 -0.11003127  0.07752805\n",
      "  -0.37240644  0.76171434]\n",
      " [ 0.35229386  0.41622915  0.57767839  0.21207202  1.00885653  0.4520619\n",
      "   0.80349008  0.61745937]\n",
      " [ 0.12347534  0.57944821  0.0780136  -0.07586306 -0.50737948  0.36582967\n",
      "   0.51575912  0.73014998]\n",
      " [ 0.42201328  0.34704091  0.96023446  0.82532686  0.68863527  0.36101636\n",
      "   0.01775739 -0.25663744]\n",
      " [-0.81928657 -1.11208499 -0.90172625 -1.29370233 -0.54525039 -0.09536048\n",
      "  -1.1251943  -0.73252751]]\n",
      "x [[-0.86022091 -0.69317955 -0.84192845 -0.91985466 -0.40603984 -0.16451621\n",
      "  -0.84862595 -0.85712298]\n",
      " [ 0.07385434  0.06276593 -0.30705476 -0.26201769  0.38148167 -0.50488995\n",
      "   0.45349388  0.2542475 ]\n",
      " [ 0.45073099  0.73339804  0.3335697   0.27352607  0.2548381   0.54054543\n",
      "   0.47090264  0.43846262]\n",
      " [ 1.03978011  1.38946168  0.89449718  1.40964554  1.06677898  1.16985012\n",
      "   0.09173347  0.76469539]\n",
      " [-1.06188296 -0.27589697  0.13032197 -0.09299976 -0.10280384 -0.32863182\n",
      "  -0.37588371 -0.91118242]\n",
      " [-0.02261074  0.30557392  0.28726528  0.24953103 -0.029898    0.5143372\n",
      "  -0.05501386 -0.2118476 ]\n",
      " [-0.01693679  0.02788303  0.42615773 -0.03772839  0.59722831  0.06674325\n",
      "   0.61323298  0.41760011]\n",
      " [ 0.01490992  0.48546336  0.12520052 -0.09455278  0.85105201 -0.17825851\n",
      "   0.18845599  0.06285888]\n",
      " [ 0.74270033  0.59449256  0.1386145   1.10150983 -0.02155911  0.62146565\n",
      "   0.2145517   0.54835021]\n",
      " [-0.77581562 -0.85835113 -1.26319626 -0.59043732 -0.31784055 -1.26516803\n",
      "  -0.78294216 -0.64997526]]\n",
      "x [[-7.64549471e-01 -7.74979724e-01 -4.83082813e-01 -5.79922536e-01\n",
      "  -7.30567373e-01 -5.28451615e-01 -4.42685072e-01 -3.86244289e-01]\n",
      " [-9.12473029e-02 -4.49523884e-01 -1.76652514e-01  3.29314462e-01\n",
      "   1.54167785e-01 -1.21709601e-01 -7.18572250e-03 -1.09875246e+00]\n",
      " [ 1.75149310e-01  2.90625029e-01  5.87345031e-01  6.85200538e-01\n",
      "   1.31972798e-01  3.78707650e-01  4.24431447e-01  4.32594943e-01]\n",
      " [ 3.11350086e-02  8.07594811e-01  5.25280387e-04  7.05704979e-01\n",
      "   3.73643837e-02  6.12517286e-01  6.09483283e-01  1.32312457e+00]\n",
      " [-3.75890700e-01  2.81649190e-02 -5.29442446e-01  9.02830002e-02\n",
      "   3.88216286e-01 -1.04039650e-01  3.98575405e-01 -3.72600060e-01]\n",
      " [-2.09787140e-01  2.41861060e-01  8.75796434e-03  6.21147950e-02\n",
      "  -4.59693515e-01  3.59069550e-01 -4.98419652e-01  6.45893335e-01]\n",
      " [ 3.64527921e-01  8.13483048e-01  3.47559500e-01  4.98885443e-01\n",
      "   5.85506205e-01  5.74487203e-01  9.74496314e-01  4.26962884e-01]\n",
      " [ 2.11116261e-01  3.14602582e-01 -5.18364650e-03  5.36889066e-01\n",
      "  -1.94672634e-02  4.01509488e-01  1.12197410e-01  1.54938523e-01]\n",
      " [ 1.52200107e-01  5.52123432e-01  7.81151845e-01  2.28549675e-01\n",
      "   4.84290448e-01  4.25927724e-01  6.95060044e-01  1.29530916e+00]\n",
      " [-4.98486954e-01 -7.39128171e-01 -6.61784091e-01 -7.14525190e-01\n",
      "  -8.80659235e-01 -7.44195568e-01 -6.82544509e-01 -7.40829176e-01]]\n",
      "x [[-3.88230350e-01 -4.75893522e-01  1.41636308e-01  2.55728125e-01\n",
      "  -5.30528523e-03 -3.77713856e-01 -1.41941310e-01 -8.33193300e-01]\n",
      " [ 1.90014722e-01  4.57922676e-02 -9.69475957e-04 -1.42583733e+00\n",
      "  -5.94824230e-01  6.22968989e-01  3.84132196e-02 -8.13033307e-02]\n",
      " [ 4.38754212e-01  4.69679627e-01  5.63396055e-01  1.12163783e+00\n",
      "   6.44329254e-02  4.55947235e-01  1.64853579e-01  1.23629258e+00]\n",
      " [ 2.84130444e-01  7.56492757e-01  8.95349609e-01  7.78173611e-01\n",
      "   3.30368114e-01  7.34676434e-01  5.61202910e-01  1.31958923e+00]\n",
      " [-5.17067975e-01 -8.97296617e-01 -6.62326098e-01 -8.88027877e-01\n",
      "   2.66485474e-02 -1.67730815e-01 -3.61193423e-01 -1.44650897e-01]\n",
      " [-4.60658685e-01  2.71676181e-01  6.10417433e-01  3.19043685e-01\n",
      "  -1.35916480e-01  1.05045020e-01 -2.44757023e-01  2.60389621e-01]\n",
      " [ 1.92608493e-02  2.93836788e-01  4.92334832e-02 -3.47967195e-01\n",
      "   4.06572635e-01  5.41399412e-02  3.99583209e-01  7.28528187e-01]\n",
      " [-4.38578902e-02  2.20117009e-01 -6.78343794e-02  5.31248316e-01\n",
      "   6.88283050e-03  1.00601763e-01  2.36163563e-01  4.95289333e-01]\n",
      " [ 6.21620620e-01  1.09289433e+00  4.37765394e-01  6.71996215e-01\n",
      "   7.13894586e-01  1.02099634e-01  7.62097550e-02  8.89515694e-01]\n",
      " [-1.00579330e+00 -1.70939746e+00 -1.09926168e+00 -9.61600166e-01\n",
      "   1.45954295e-01 -1.17941499e+00 -4.40522625e-01 -5.38861026e-01]]\n",
      "x [[ 3.75999350e-02 -3.95716406e-01 -4.42684594e-01 -7.40113454e-01\n",
      "  -5.33569440e-01 -6.84442612e-01 -7.09288702e-01  2.30421036e-01]\n",
      " [-1.21112128e+00  1.05093554e-01 -2.60888532e-01 -2.86849566e-01\n",
      "  -2.85152782e-01 -2.03530289e-02 -2.48168033e-02 -7.06548972e-01]\n",
      " [ 4.72324233e-01  5.41136823e-02 -2.76410525e-01  3.54652902e-01\n",
      "  -2.61118037e-01  1.10634629e-01  1.01719062e-01  7.03331980e-01]\n",
      " [ 3.26366591e-01  7.79635366e-01  5.25429020e-01  1.01446112e+00\n",
      "   3.28473374e-01  1.19548284e+00  8.95394136e-01  9.48558318e-01]\n",
      " [-5.01598382e-01  2.33160818e-01 -6.98316664e-02 -5.52209647e-01\n",
      "  -6.74377912e-01 -2.95588107e-01 -4.32434624e-02 -3.92519846e-01]\n",
      " [ 4.95916436e-02  7.71868690e-01  3.00846821e-01  6.44337605e-01\n",
      "   2.05736969e-01  1.03494328e-01  6.04623020e-04 -1.87445600e-01]\n",
      " [-4.11914436e-02  5.59279158e-01  6.67312609e-01  3.38582056e-01\n",
      "   5.71610033e-02  3.72834936e-01  7.21650697e-01 -3.22270825e-01]\n",
      " [ 4.00638457e-01  4.52630853e-01  7.62486030e-02  1.42195949e-01\n",
      "   2.09676327e-01  2.08019772e-01  5.53954861e-01  5.59812839e-01]\n",
      " [ 3.41772924e-01  4.82037533e-01  3.52052754e-01  4.82255837e-01\n",
      "  -7.75369657e-01  4.41275851e-01  2.37525218e-01  6.13606441e-01]\n",
      " [-6.50863754e-01 -3.78585959e-01 -8.52783855e-01 -9.67756758e-01\n",
      "  -1.11920435e+00 -1.65380018e-01 -5.54167723e-01 -2.34413934e-01]]\n",
      "x [[-0.01907493 -0.47622492 -0.54594071 -0.67447476  0.43353826 -0.2311842\n",
      "  -0.2748121  -0.06757241]\n",
      " [-0.51481097  0.1662906   0.10066723 -0.01127241 -0.88575815  0.04255935\n",
      "   0.12620619  0.12568042]\n",
      " [ 0.11781269  0.3370445   0.15848119  0.06284934  0.05162312  0.17287922\n",
      "   0.0686805   0.60741969]\n",
      " [ 0.90800742  1.48721028  0.90589472  0.52562432 -0.04225161  0.26481866\n",
      "   0.85529365  0.8330573 ]\n",
      " [-0.45214675 -0.19583093 -0.13288768 -0.80982288 -0.73018272  0.09044268\n",
      "  -0.43113316 -0.21692546]\n",
      " [-0.56991654  0.0375535  -0.06984242  0.24264933  0.54631829 -0.2545147\n",
      "  -0.10424325 -0.03256014]\n",
      " [ 0.59061363  0.42786927  0.58413701  0.13698556 -0.23176395  0.1319742\n",
      "   0.41526141  0.15285747]\n",
      " [ 0.51463142  0.19453702  0.03209381  0.06832604  0.22818043 -0.6970933\n",
      "   0.59242312  0.42342957]\n",
      " [-0.28535187  0.54344767 -0.15075068 -0.18307518 -0.48455461  0.73674433\n",
      "   0.17479759  0.47021977]\n",
      " [ 0.06271263 -0.3197737  -0.80693968 -0.55904253 -1.05981832 -0.50040059\n",
      "   0.18107643 -0.29436443]]\n",
      "Iter: 8 Loss: 2.323590566135019\n",
      "x [[-0.3788927  -0.40253094  0.05934423  0.46939162 -0.52203326 -1.02367914\n",
      "  -0.49041992 -0.05213269]\n",
      " [ 0.20362529  0.11707293  0.05660746 -0.50637281 -0.47560681  0.01284189\n",
      "  -0.00239676  0.14495953]\n",
      " [ 0.10686723  0.12861749  0.09284852  0.3232769  -0.23141241  0.41298789\n",
      "   0.63092783  0.42061552]\n",
      " [ 0.46310254  0.64775104  0.23570975  0.6673872  -0.07663314  1.00470362\n",
      "   0.62425444  0.56990133]\n",
      " [-0.48231291  0.12115535  0.13372609  0.0466784  -0.12519325 -0.1780214\n",
      "  -0.19237051 -0.19224289]\n",
      " [-0.16638336 -0.08491339 -0.29745056  0.44778135  0.38154107  0.50333535\n",
      "   0.6332111   0.64959567]\n",
      " [ 0.22531114  0.23191928  0.13772705 -0.33495049  1.19420892  0.29666591\n",
      "   0.16973791  0.04601098]\n",
      " [ 0.39972697  0.36970783  0.04693489 -0.26364557 -0.31820728 -0.24323498\n",
      "  -0.13565935  0.85011826]\n",
      " [-0.10080078 -0.10524864  0.53399874  0.55359344 -0.10758893  0.19439535\n",
      "   0.14485241  0.80373276]\n",
      " [-0.05954964 -0.49743464 -1.02094083 -0.69115793 -0.53943733 -0.75473551\n",
      "  -0.77551069 -0.35714855]]\n",
      "x [[ 0.26301207  0.28173961  0.00532246  0.15692809 -0.82442287 -0.32958166\n",
      "  -0.65031955 -0.57290649]\n",
      " [-0.21241803 -0.52834321 -0.77343507  0.12745634 -0.37790142 -0.05536113\n",
      "   0.39058578 -0.5485126 ]\n",
      " [ 0.46515187  0.10285367  0.01193983  0.42299663 -0.55649514 -0.05181044\n",
      "   0.22257434  0.2287791 ]\n",
      " [ 0.46824615  0.35757147  0.30481142  0.82652841 -0.37039336  0.22047123\n",
      "  -0.29197563  0.69398801]\n",
      " [-0.36366925  0.27588204 -0.76326243 -0.43566872 -0.30885309 -0.05616702\n",
      "  -0.56428404  0.22378536]\n",
      " [-0.12965513 -0.3035984  -0.13054831  0.46981128  0.05392384  0.28260625\n",
      "   0.09538419 -0.23612794]\n",
      " [-0.27596385  0.41894594  0.22721194 -0.12940714  1.00479946  0.0396868\n",
      "   0.44388554  0.57055604]\n",
      " [-0.13289557 -0.45445331  0.05390167  0.43882347  0.0862201   0.48436915\n",
      "  -0.13033853  0.6066414 ]\n",
      " [ 0.30446722  0.26809872 -0.1257549  -0.22162286  0.76866547  0.4208634\n",
      "   0.17848237  0.12503999]\n",
      " [-0.62183793 -0.89472807 -0.94215636 -0.31959901 -0.52227511 -1.13921694\n",
      "  -1.55439824  0.34229795]]\n",
      "x [[ 0.76467731 -0.06470838 -0.23666848  0.19796154 -0.47933881 -0.07578136\n",
      "  -0.43265195  0.87411261]\n",
      " [-1.09493645 -0.6434472   0.1164789   0.11736107  0.36434328  0.33734986\n",
      "   0.56396987 -0.76452293]\n",
      " [ 0.61093546  0.53728163  0.22852535  0.17990754 -0.32843002  0.12087043\n",
      "   0.45553714  0.42902785]\n",
      " [ 0.11491932  0.75640899  0.81162376  0.39399264  0.46428543  0.409187\n",
      "   0.61356572  0.43460749]\n",
      " [-0.75731368 -0.15373953 -0.47796322 -0.15215539 -0.15026149 -0.31384931\n",
      "   0.00110605  0.09757005]\n",
      " [ 0.04406062 -0.30967644 -0.65309966  0.0896396   0.03034187 -0.13177127\n",
      "  -0.25691397  0.06075912]\n",
      " [-0.4446195   0.56291256  0.98467486 -0.4436335   0.37330599  0.37309785\n",
      "   0.47908634  0.28255509]\n",
      " [ 0.17064678  0.67262564  0.38347443  0.39673192  0.31157862  0.31520766\n",
      "   0.65650506 -0.58611743]\n",
      " [-0.42493924 -0.07850082 -0.15043364  0.33619504  0.43556869 -0.05604313\n",
      "   0.50128176  0.67177692]\n",
      " [-0.85235672  0.34739142 -0.31146973 -0.3782583  -0.66457872 -0.3806995\n",
      "  -0.08806657 -0.56688769]]\n",
      "x [[-0.41986818 -0.50275191  0.44363965 -0.40547272 -0.51985217  0.54098779\n",
      "  -0.2354507   0.00289088]\n",
      " [ 0.00430696 -0.11890137  0.38340952  0.24240716  0.32973637 -0.74775662\n",
      "   0.37198622 -0.36885791]\n",
      " [ 0.10475169  0.39307847  0.00490426  0.49999459  0.05476187  0.18054213\n",
      "  -0.02193712  0.16002292]\n",
      " [ 0.12403612  0.39008935 -0.0856739   0.63459141  0.61638146  0.05319322\n",
      "   0.52887567  0.2433611 ]\n",
      " [-0.16776523  0.23029666 -0.14604111 -0.35189264  1.19638156 -0.06377522\n",
      "  -0.17283263  0.30805137]\n",
      " [ 0.40811354  0.06019854 -0.36656418  0.16070692  0.11963055 -0.03367136\n",
      "  -0.33308412  0.31887424]\n",
      " [ 0.40682732  0.49418829  0.05093894  0.02405739  0.96965988 -0.1173839\n",
      "   0.34312329  0.23184739]\n",
      " [ 0.13473659  0.35322695 -0.21933041  0.23156085  0.35898831  0.20200411\n",
      "   0.4451032   0.27998062]\n",
      " [ 1.21187702  0.51027223  0.64935505 -0.06144693  0.44987084  0.44334274\n",
      "  -0.07652517  0.4633438 ]\n",
      " [-0.10316826 -0.4450001  -1.26945543 -0.66946125  0.42011981 -0.32681863\n",
      "   0.13108454 -0.16898255]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m dout \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_y)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m conv, fc1_grad, fc2_grad \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[1;32m     28\u001b[0m model\u001b[38;5;241m.\u001b[39mupdate_weights(conv, fc1_grad, fc2_grad, lr)\n",
      "Cell \u001b[0;32mIn[9], line 28\u001b[0m, in \u001b[0;36mNeuralNet.backward\u001b[0;34m(self, dout)\u001b[0m\n\u001b[1;32m     26\u001b[0m dx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool1\u001b[38;5;241m.\u001b[39mbackward(dx)\n\u001b[1;32m     27\u001b[0m dx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu1\u001b[38;5;241m.\u001b[39mbackward(dx)\n\u001b[0;32m---> 28\u001b[0m dx, conv_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conv_grad, fc1_grad, fc2_grad\n",
      "Cell \u001b[0;32mIn[6], line 30\u001b[0m, in \u001b[0;36mConvLayer.backward\u001b[0;34m(self, dout)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):  \u001b[38;5;66;03m# out_channels\u001b[39;00m\n\u001b[1;32m     29\u001b[0m             dx[:, :, i\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride:i\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], j\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride:j\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m]] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw[k, :, :, :] \u001b[38;5;241m*\u001b[39m dout[:, k, i, j][:, np\u001b[38;5;241m.\u001b[39mnewaxis, np\u001b[38;5;241m.\u001b[39mnewaxis, np\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[0;32m---> 30\u001b[0m             dw[k, :, :, :] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_slice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdout\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dx[:, :, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding:\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding:\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding], dw\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/lib/python3.11/site-packages/numpy/_core/fromnumeric.py:2250\u001b[0m, in \u001b[0;36m_sum_dispatcher\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2180\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2181\u001b[0m \u001b[38;5;124;03m    Clip (limit) the values in an array.\u001b[39;00m\n\u001b[1;32m   2182\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2245\u001b[0m \n\u001b[1;32m   2246\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m'\u001b[39m, a_min, a_max, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 2250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum_dispatcher\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2251\u001b[0m                     initial\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, out)\n\u001b[1;32m   2255\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_sum_dispatcher)\n\u001b[1;32m   2256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2257\u001b[0m         initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Training parameters\n",
    "batch_size = 8\n",
    "epochs = 5\n",
    "lr = 1e-3  # Further reduced learning rate\n",
    "\n",
    "model = NeuralNet()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        batch_X = X_train[i:i+batch_size]\n",
    "        batch_y = y_train[i:i+batch_size]\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model.forward(batch_X)\n",
    "\n",
    "        # Compute loss and gradients\n",
    "        loss = cross_entropy_loss(y_pred, batch_y)\n",
    "        dout = softmax(y_pred)\n",
    "        dout[batch_y, range(len(batch_y))] -= 1\n",
    "        dout /= len(batch_y)\n",
    " \n",
    "        # Backward pass\n",
    "        conv, fc1_grad, fc2_grad = model.backward(dout)\n",
    "\n",
    "        # Update weights\n",
    "        model.update_weights(conv, fc1_grad, fc2_grad, lr)\n",
    "\n",
    "        if i % 64 == 0:\n",
    "            print(f\"Iter: {i//batch_size} Loss: {loss}\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    y_pred = model.forward(X_test)\n",
    "    test_loss = cross_entropy_loss(y_pred, y_test)\n",
    "    accuracy = np.mean(np.argmax(y_pred, axis=0) == y_test)\n",
    "    print(f\"Epoch {epoch+1} - Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
